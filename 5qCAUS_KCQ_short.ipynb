{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Envirionment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas\n",
    "# ! pip install openai\n",
    "# ! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('openai_api_key.txt', 'r') as f:\n",
    "    openai.api_key = f.read().strip()\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
    "\n",
    "# os.environ.get(\"OPENAI_API_KEY\") # api_key check if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing required files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-4-0613\", temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call prompts\n",
    "with open('ktype_prompt.txt', 'r') as fk:\n",
    "    kt_prompt = fk.read()\n",
    "with open('ctype_prompt.txt', 'r') as fc:\n",
    "    ct_prompt = fc.read()\n",
    "with open('qtype_prompt.txt', 'r') as fq:\n",
    "    qt_prompt = fq.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call intermediate file \n",
    "interm_FileName = \"CAUS\" \n",
    "with open(f'_output_intermediate/intermediate_{interm_FileName}.json', 'r') as file:\n",
    "    intermediate_json = json.load(file)\n",
    "print(len(intermediate_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop for KCQ-typing from the intermediate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_intermediate(intermediate_data, prompt, key_name):\n",
    "    intermediate_results = []\n",
    "    \n",
    "    for item in intermediate_data:\n",
    "        row_dict = item['row_dict']\n",
    "        query_value = item['query_value']\n",
    "\n",
    "        messages = [SystemMessage(content=f\"'{prompt}'\"), HumanMessage(content=f\"'{query_value}'\")]\n",
    "        response_str = chat(messages).content\n",
    "        matches = re.findall(r\"\\(([^)]+)\\)\", response_str)\n",
    "        response_tuples = [tuple(map(lambda x: x.strip().strip(\"'\"), match.split(','))) for match in matches]\n",
    "\n",
    "        intermediate_results.append({\n",
    "            \"row_dict\": row_dict,\n",
    "            \"query_value\": query_value,\n",
    "            key_name: response_tuples\n",
    "        })\n",
    "\n",
    "        # Sleep for 0.8 seconds after processing each item\n",
    "        time.sleep(0.8)\n",
    "    \n",
    "    return intermediate_results\n",
    "\n",
    "# Process ktype, ctype, and qtype for each query_value\n",
    "ktype_intermediate = process_intermediate(intermediate_json, kt_prompt, \"ktype\")\n",
    "ctype_intermediate = process_intermediate(intermediate_json, ct_prompt, \"ctype\")\n",
    "qtype_intermediate = process_intermediate(intermediate_json, qt_prompt, \"qtype\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the final results\n",
    "output = []\n",
    "\n",
    "# Assume qtype_intermediate and ktype_intermediate have the same length\n",
    "for k_item, c_item, q_item, int_item in zip(ktype_intermediate, ctype_intermediate, qtype_intermediate, intermediate_json):\n",
    "    # Check if the 'row_dict' values of each item are the same\n",
    "    assert k_item['row_dict'] == c_item['row_dict'] == q_item['row_dict'] == int_item['row_dict'], \"row_dict values do not match!\"\n",
    "\n",
    "    row_dict = q_item['row_dict']\n",
    "    reasoning = int_item['reasoning']  \n",
    "    questions_list = []\n",
    "    \n",
    "    for idx, (query, ktype_tuple, ctype_tuple, qtype_tuple) in enumerate(zip(q_item['query_value'], k_item['ktype'], c_item['ctype'], q_item['qtype']), start=1):\n",
    "\n",
    "        ktype_num, ktype_text = ktype_tuple\n",
    "        ctype_num, ctype_text = ctype_tuple\n",
    "        qtype_num, qtype_text = qtype_tuple\n",
    "                \n",
    "        question_dict = {\n",
    "            f\"qid{idx:02}\": f\"{row_dict['scn_id']}Q{idx:02}\",\n",
    "            f\"query{idx:02}\": query,\n",
    "            f\"ktype_num{idx:02}\": ktype_num,\n",
    "            f\"ktype{idx:02}\": ktype_text,\n",
    "            f\"ctype_num{idx:02}\": ctype_num,\n",
    "            f\"ctype{idx:02}\": ctype_text,\n",
    "            f\"qtype_num{idx:02}\": qtype_num,\n",
    "            f\"qtype{idx:02}\": qtype_text\n",
    "        }\n",
    "        \n",
    "        questions_list.append(question_dict)\n",
    "    \n",
    "    output_dict = {\n",
    "        \"scn_id\": row_dict[\"scn_id\"],\n",
    "        \"scn_cls\": row_dict[\"scn_cls\"],\n",
    "        \"scn_sentence\": row_dict[\"scn_sentence\"],\n",
    "        \"reasoning\": reasoning, \n",
    "        \"question\": questions_list\n",
    "    }\n",
    "\n",
    "    output.append(output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving output to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the JSON output to a file\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "nowdate = now.strftime(\"%y%m%d_%H%M%S\")\n",
    "\n",
    "with open(f'_output_result/result_{interm_FileName}_{nowdate}_35turbo.json', 'w') as json_file:\n",
    "    json.dump(output, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving CSV with qid and qtypes of each question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_output = []\n",
    "\n",
    "for entry in output:\n",
    "        new_dict = entry.copy() # Create a copy of the existing dictionary  \n",
    "        questions = new_dict.pop('question') # Extract the \"question\" item\n",
    "        for q_dict in questions:\n",
    "            new_dict.update(q_dict) # Move items from each sub-dictionary to the parent dictionary\n",
    "\n",
    "        transformed_output.append(new_dict) # Add the modified dictionaries to a new list\n",
    "\n",
    "# Create a DataFrame using the new list\n",
    "df_output = pd.DataFrame(transformed_output)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_output.to_csv(f'_output_result/result_{interm_FileName}_for35turbo_{nowdate}_35turbo.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
